{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expressions\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY = \"bitcoin\"\n",
    "CURRENCY_SYMBOL = \"BTC\"\n",
    "tweets_raw_file = f'data/twitter/{CURRENCY_SYMBOL}/{CURRENCY}_tweets_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(tweets_raw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d.drop(['ID','UserName','UserFollowerCount','RetweetCount','Likes','CreatedAt'],axis=1)\n",
    "d1 = d1.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1= d1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.replace(u\"ï¿½\", \"?\")\n",
    "        #bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        print(\"failed\")\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "testing = d1.Text[:100]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner_updated(t))\n",
    "#test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 43250 has been processed\n",
      "Tweets 20000 of 43250 has been processed\n",
      "Tweets 30000 of 43250 has been processed\n",
      "Tweets 40000 of 43250 has been processed\n"
     ]
    }
   ],
   "source": [
    "nums = [0,d1.shape[0]]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(d1['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>become bitcoin developer basic via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btc buying pressure alert price trading around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt embarrassed to say shorted bitcoin yesterda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt hpt price usdt hpt trading pairs hpt volume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt ll give btc or paypal to someone who retwee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 become bitcoin developer basic via\n",
       "1  btc buying pressure alert price trading around...\n",
       "2  rt embarrassed to say shorted bitcoin yesterda...\n",
       "3  rt hpt price usdt hpt trading pairs hpt volume...\n",
       "4  rt ll give btc or paypal to someone who retwee..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean_file = f'data/twitter/{CURRENCY_SYMBOL}/{CURRENCY}_tweets_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(tweets_clean_file,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(tweets_clean_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>become bitcoin developer basic via</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btc buying pressure alert price trading around...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt embarrassed to say shorted bitcoin yesterda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt hpt price usdt hpt trading pairs hpt volume...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt ll give btc or paypal to someone who retwee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                 become bitcoin developer basic via       0\n",
       "1  btc buying pressure alert price trading around...       0\n",
       "2  rt embarrassed to say shorted bitcoin yesterda...       0\n",
       "3  rt hpt price usdt hpt trading pairs hpt volume...       0\n",
       "4  rt ll give btc or paypal to someone who retwee...       0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# initializing spark session\n",
    "sc = SparkContext(appName=\"PySparkShell\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+-----------------+------------+-----+--------------------+\n",
      "|                 ID|                Text|    UserName|UserFollowerCount|RetweetCount|Likes|           CreatedAt|\n",
      "+-------------------+--------------------+------------+-----------------+------------+-----+--------------------+\n",
      "|               null|                null|        null|             null|        null| null|                null|\n",
      "|1256595810265051136|Become A Bitcoin ...| Naked Wicks|               22|           0|    0|Sat May 02 14:46:...|\n",
      "|1256595809077874688|⬆️⬆️ $BTC BUYING ...|CryptoSquawk|              284|           0|    0|Sat May 02 14:46:...|\n",
      "|1256595805978284032|RT : I'm embarras...|    kjvbbnnn|                0|           5|    0|Sat May 02 14:46:...|\n",
      "|1256595802736046081|RT : HPT Price US...|         kim|               67|          27|    0|Sat May 02 14:46:...|\n",
      "+-------------------+--------------------+------------+-----------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- UserName: string (nullable = true)\n",
      " |-- UserFollowerCount: integer (nullable = true)\n",
      " |-- RetweetCount: integer (nullable = true)\n",
      " |-- Likes: integer (nullable = true)\n",
      " |-- CreatedAt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_schema = tp.StructType([\n",
    "  tp.StructField(name= 'ID',          dataType= tp.StringType(),  nullable= True),\n",
    "  tp.StructField(name= 'Text',       dataType= tp.StringType(),  nullable= True),\n",
    "  tp.StructField(name= 'UserName',       dataType= tp.StringType(),   nullable= True),\n",
    "  tp.StructField(name= 'UserFollowerCount',          dataType= tp.IntegerType(),  nullable= True),\n",
    "  tp.StructField(name= 'RetweetCount',          dataType= tp.IntegerType(),  nullable= True),\n",
    "  tp.StructField(name= 'Likes',          dataType= tp.IntegerType(),  nullable= True),\n",
    "  tp.StructField(name= 'CreatedAt',          dataType= tp.StringType(),  nullable= True),\n",
    "])\n",
    "\n",
    "my_data = spark.read.csv(tweets_clean_file,\n",
    "                         schema=my_schema,\n",
    "                         header=True)\n",
    "#view the data\n",
    "my_data.show(5)\n",
    "\n",
    "#print the schema of the file\n",
    "my_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = RegexTokenizer(inputCol= 'Text' , outputCol= 'tokens', pattern= '\\\\W')\n",
    "# define stage 2: remove the stop words\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')\n",
    "# define stage 3: create a word vector of the size 100\n",
    "stage_3 = Word2Vec(inputCol= 'filtered_words', outputCol= 'vector', vectorSize= 100)\n",
    "# define stage 4: Logistic Regression Model\n",
    "model = LogisticRegression(featuresCol= 'vector', labelCol= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('LSP': conda)",
   "language": "python",
   "name": "python361064bitlspcondad95b3df7e1b14d0b82b89f2d70e6b4d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
